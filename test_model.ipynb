{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_pickle(\"./data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'title'\n",
    "data = data.filter([target_feature + \"_vector\", 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        title_vector  label\n",
       "0  [[0.6595936, 0.51315624, 0.29930714, 0.0358353...      1\n",
       "1  [[0.61800295, 0.31473106, -0.6350405, 0.099915...      1\n",
       "2  [[0.13825978, 0.3021639, -0.3671617, 0.0290168...      1\n",
       "3  [[0.47920132, 0.52537596, -0.5724726, 0.432976...      1\n",
       "4  [[0.79335517, 0.23477861, -0.13257661, -0.1356...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_vector</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[0.6595936, 0.51315624, 0.29930714, 0.0358353...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[0.61800295, 0.31473106, -0.6350405, 0.099915...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[0.13825978, 0.3021639, -0.3671617, 0.0290168...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[0.47920132, 0.52537596, -0.5724726, 0.432976...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[0.79335517, 0.23477861, -0.13257661, -0.1356...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                           title_vector  label\n3463  [[0.5552156, -0.16965698, -0.38498297, 0.41805...      0\n1544  [[0.7770728, 0.691371, -0.5617533, 0.24750076,...      0\n2578  [[0.22808988, 0.060332485, -0.5020853, 0.18747...      0\n3528  [[0.6334721, 0.32261947, -0.20044172, -0.18055...      1\n589   [[0.2520358, 0.16787434, -0.29778117, 0.075333...      1\n...                                                 ...    ...\n4212  [[0.87619215, 0.45379844, -0.122751236, -0.305...      1\n2687  [[0.97706026, -0.30546528, -0.015893033, -0.20...      0\n2119  [[0.6905516, 0.085860595, 0.030321244, -0.0475...      1\n4017  [[0.26876533, 0.2418903, -0.06839772, 0.098044...      0\n2982  [[0.54721344, 0.015975937, -0.43114954, 0.1802...      0\n\n[2809 rows x 2 columns]\n                                           title_vector  label\n91    [[-0.10758181, 0.56745625, -0.2987436, 0.14264...      1\n4187  [[0.5947004, -0.34817788, -0.1250591, 0.287285...      1\n2507  [[0.38071847, 0.5159382, -0.0494503, -0.225324...      1\n1808  [[0.6525312, -0.32875022, -0.14181589, 0.14258...      1\n2953  [[0.10483644, -0.11899833, -0.2072039, -0.1604...      1\n...                                                 ...    ...\n2525  [[0.72004604, 0.10059118, -0.25519353, -0.0918...      1\n3582  [[0.43891245, 0.58768106, 0.30850816, -0.45524...      0\n3153  [[0.66252255, 0.047511425, -0.6763533, 0.21796...      0\n858   [[0.2544659, -0.04454496, -0.32164693, 0.00470...      1\n2852  [[0.21602213, 0.08566885, -0.29157916, 0.34729...      0\n\n[1513 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, random_state=777, train_size=0.65)\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_data[target_feature + \"_vector\"].iloc[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2809, 768)\n(2809, 1)\n(1513, 768)\n(1513, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data[target_feature + \"_vector\"].values\n",
    "y_train = train_data['label'].values\n",
    "x_train = np.vstack(x_train)\n",
    "y_train = np.vstack(y_train)\n",
    "\n",
    "x_test = test_data[target_feature + \"_vector\"].values\n",
    "y_test = test_data['label'].values\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1\n",
      "acc: 95.37%\n",
      "F1 Score: 95.24%\n",
      "Confusion Matrix:\n",
      " [[276  18]\n",
      " [  8 260]]\n",
      "\n",
      "\n",
      "Fold 2\n",
      "acc: 95.55%\n",
      "F1 Score: 95.33%\n",
      "Confusion Matrix:\n",
      " [[282  12]\n",
      " [ 13 255]]\n",
      "\n",
      "\n",
      "Fold 3\n",
      "acc: 93.59%\n",
      "F1 Score: 93.31%\n",
      "Confusion Matrix:\n",
      " [[275  19]\n",
      " [ 17 251]]\n",
      "\n",
      "\n",
      "Fold 4\n",
      "acc: 95.37%\n",
      "F1 Score: 95.22%\n",
      "Confusion Matrix:\n",
      " [[277  16]\n",
      " [ 10 259]]\n",
      "\n",
      "\n",
      "Fold 5\n",
      "acc: 96.26%\n",
      "F1 Score: 96.12%\n",
      "Confusion Matrix:\n",
      " [[280  13]\n",
      " [  8 260]]\n",
      "\n",
      "\n",
      "Average accuracy : 95.23% (+/- 0.88%)\n",
      "Average F1 score : 95.04% (+/- 0.93%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cvscores = []\n",
    "f1_scores = []\n",
    "count = 1\n",
    "input_dim = x_train.shape[1]\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    print(\"Fold {}\".format(count))\n",
    "    count += 1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(optimizer = adam,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=5, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "    y_pred = model.predict_classes(x_train[test], verbose=0)\n",
    "    f1 = f1_score(y_train[test], y_pred)\n",
    "    confmat = confusion_matrix(y_train[test], y_pred)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"F1 Score: %.2f%%\" % (np.mean(f1*100)))\n",
    "    print(\"Confusion Matrix:\\n {}\".format(confmat))\n",
    "    print(\"\\n\")\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    f1_scores.append(f1 * 100)\n",
    "print(\"Average accuracy : %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"Average F1 score : %.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1513/1513 [==============================] - 0s 17us/step\n",
      "Evaluate on test data\n",
      "test loss, test acc: [0.2525048043679813, 0.8975545274683441]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"Evaluate on test data\")\n",
    "print(\"test loss, test acc:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}